{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This Colab notebook supports inference with a [so-vits-svc-fork-4.0](https://github.com/34j/so-vits-svc-fork) model"
      ],
      "metadata": {
        "id": "utpOPXLk-_B0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparations"
      ],
      "metadata": {
        "id": "vCon-D1txcXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "wPqvtZ8qYXRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nup6u24LoSKD"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "#@markdown pip may fail to resolve dependencies and raise ERROR, but it can be ignored.\n",
        "!python -m pip install -U pip wheel\n",
        "# %pip install -U ipython\n",
        "%pip install -U so-vits-svc-fork\n",
        "%pip install -U demucs\n",
        "# !apt install ffmpeg\n",
        "%pip install yt-dlp\n",
        "import subprocess\n",
        "i = 1 #flag for renaming copies of songs\n",
        "from IPython.display import Audio, display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download pretrained model\n",
        "# Model of Chen Zhuoxuan is available at https://huggingface.co/melicat/so-vits-svc-4.0/tree/main/ChenZhuoxuan\n",
        "!wget -N 'https://huggingface.co/melicat/so-vits-svc-4.0/resolve/main/ChenZhuoxuan/G_30400.pth'\n",
        "!wget -N 'https://huggingface.co/melicat/so-vits-svc-4.0/resolve/main/ChenZhuoxuan/config.json'"
      ],
      "metadata": {
        "id": "d15BifXIowAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have the song in your computer, upload to session storage or Google Drive.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1qM5guKsAoGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer a song"
      ],
      "metadata": {
        "id": "Y1lvXatYDPOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download input song from YouTube\n",
        "YouTubeLink = 'https://youtu.be/FzZSADo_uxA' #@param {'type': 'string'}\n",
        "#@markdown Singing clips with very simple accompaniment (e.g. only one guitar or piano) are preferred.\n",
        "!yt-dlp {YouTubeLink}\n",
        "videoName = subprocess.getoutput(f'yt-dlp --print filename {YouTubeLink}')\n",
        "!ffmpeg -y -i \"{videoName}\" -ar 44100 song.mp3"
      ],
      "metadata": {
        "id": "hOqACABo8TPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Separation into vocals/accompaniment\n",
        "#@markdown Here, we use [demucs](https://github.com/facebookresearch/demucs) to isolate the vocals. For GUI and potentially better separation, use [UVR](https://ultimatevocalremover.com) (Extract vocals with 3_HP-Vocal-UVR and remove backing vocals with 5_HP-Karaoke-UVR).\n",
        "# # spleeter is an alternative to demucs, but may cause dependency conflicts with so-vits-svc-fork\n",
        "# %pip install spleeter\n",
        "# !spleeter separate -o /content song.mp3\n",
        "\n",
        "demucs_model = 'htdemucs_ft' #@param ['htdemucs', 'htdemucs_ft', 'htdemucs_6s', 'htdemucs_mmi', 'mdx_extra']\n",
        "!demucs -n {demucs_model} --two-stems=vocals song.mp3"
      ],
      "metadata": {
        "id": "wuV3TIIUT8aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference\n",
        "inputVocals = f'/content/separated/{demucs_model}/song/vocals.wav'\n",
        "F0_METHOD = 'crepe' #@param ['crepe', 'crepe-tiny', 'parselmouth', 'dio', 'harvest']\n",
        "transpose = 0 #@param {'type': 'integer'}\n",
        "#@markdown Sometimes the song needs to be up-transposed to fit AI Zhuoxuan's vocal range, with the accompaniment pitch-shifted accordingly.\n",
        "\n",
        "!svc infer {inputVocals} -fm {F0_METHOD} -t {transpose} -na --speaker 'czx' -m /content/G_30400.pth -c /content/config.json\n",
        "# Change -na to -a to enable auto-predict-f0 (but the result may become out of tune)"
      ],
      "metadata": {
        "id": "ROKWP6s6xLRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Combine output vocals with accompaniment\n",
        "outputVocals = f'/content/separated/{demucs_model}/song/vocals.out.wav'\n",
        "accompaniment_0 = f'/content/separated/{demucs_model}/song/no_vocals.wav'\n",
        "\n",
        "if transpose==0:\n",
        "  accompaniment = accompaniment_0\n",
        "else:\n",
        "  accompaniment = f'/content/separated/{demucs_model}/song/no_vocals_trans.wav'\n",
        "  r = pow(2,transpose/12)\n",
        "  !ffmpeg -y -i {accompaniment_0} -af asetrate=44100*{r},aresample=44100,atempo=1/{r} {accompaniment}\n",
        "\n",
        "outputSong = 'outputSong.mp3'\n",
        "!ffmpeg -y -i {outputVocals} -i {accompaniment} -filter_complex amerge=inputs=2 -ac 2 {outputSong}\n",
        "\n",
        "# Numbered copies of the files are saved before the next inference to avoid inadvertent overwriting\n",
        "rename = f'song{i}'\n",
        "!cp outputSong.mp3 'output{rename}.mp3'\n",
        "!cp song.mp3 '{rename}.mp3'\n",
        "!cp -R /content/separated/{demucs_model}/song /content/separated/{demucs_model}/{rename}\n",
        "i+=1"
      ],
      "metadata": {
        "id": "DDjlOoJ_KuTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Play output"
      ],
      "metadata": {
        "id": "CYmo3zkHFd4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# play the latest output\n",
        "print(f'Playing output{rename}.mp3')\n",
        "display(Audio(f'output{rename}.mp3', autoplay=True))"
      ],
      "metadata": {
        "id": "FVny-COqiTut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # play one of the files\n",
        "# !ffmpeg -y -i /content/separated/htdemucs_ft/song2/vocals.wav temp.mp3\n",
        "# display(Audio('temp.mp3', autoplay=True))"
      ],
      "metadata": {
        "id": "x_D3j5SvrAEy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}